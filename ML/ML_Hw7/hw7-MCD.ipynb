{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cFq_TgWlQ_"
      },
      "source": [
        "# Homework 11 - Transfer Learning (Domain Adversarial Training)\n",
        "\n",
        "> Author: Arvin Liu (r09922071@ntu.edu.tw)\n",
        "\n",
        "若有任何問題，歡迎來信至助教信箱 kafuchino0410@gmail.com\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vNiZCGrIYKdR"
      },
      "source": [
        "# Readme\n",
        "\n",
        "\n",
        "這份作業的任務是Transfer Learning中的Domain Adversarial Training。\n",
        "\n",
        "<img src=\"https://i.imgur.com/iMVIxCH.png\" width=\"500px\">\n",
        "\n",
        "> 也就是左下角的那一塊。\n",
        "\n",
        "## Scenario and Why Domain Adversarial Training\n",
        "你現在有Source Data + label，其中Source Data和Target Data可能有點關係，所以你想要訓練一個model做在Source Data上並Predict在Target Data上。\n",
        "\n",
        "但這樣有什麼樣的問題? 相信大家學過Anomaly Detection就會知道，如果有data是在Source Data沒有出現過的(或稱Abnormal的)，那麼model大部分都會因為不熟悉這個data而可能亂做一發。 \n",
        "\n",
        "以下我們將model拆成Feature Extractor(上半部)和Classifier(下半部)來作例子:\n",
        "<img src=\"https://i.imgur.com/IL0PxCY.png\" width=\"500px\">\n",
        "\n",
        "整個Model在學習Source Data的時候，Feature Extrator因為看過很多次Source Data，所以所抽取出來的Feature可能就頗具意義，例如像圖上的藍色Distribution，已經將圖片分成各個Cluster，所以這個時候Classifier就可以依照這個Cluster去預測結果。\n",
        "\n",
        "但是在做Target Data的時候，Feature Extractor會沒看過這樣的Data，導致輸出的Target Feature可能不屬於在Source Feature Distribution上，這樣的Feature給Classifier預測結果顯然就不會做得好。\n",
        "\n",
        "## Domain Adversarial Training of Nerural Networks (DaNN)\n",
        "基於如此，是不是只要讓Soucre Data和Target Data經過Feature Extractor都在同個Distribution上，就會做得好了呢? 這就是DaNN的主要核心。\n",
        "\n",
        "<img src=\"https://i.imgur.com/vrOE5a6.png\" width=\"500px\">\n",
        "\n",
        "我們追加一個Domain Classifier，在學習的過程中，讓Domain Classifier去判斷經過Feature Extractor後的Feature是源自於哪個domain，讓Feature Extractor學習如何產生Feature以**騙過**Domain Classifier。 持久下來，通常Feature Extractor都會打贏Domain Classifier。(因為Domain Classifier的Input來自於Feature Extractor，而且對Feature Extractor來說Domain&Classification的任務並沒有衝突。)\n",
        "\n",
        "如此一來，我們就可以確信不管是哪一個Domain，Feature Extractor都會把它產生在同一個Feature Distribution上。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3-qnUkspmap3"
      },
      "source": [
        "# Data Introduce\n",
        "\n",
        "這次的任務是Source Data: 真實照片，Target Data: 手畫塗鴉。\n",
        "\n",
        "我們必須讓model看過真實照片以及標籤，嘗試去預測手畫塗鴉的標籤為何。\n",
        "\n",
        "資料位於[這裡](https://drive.google.com/file/d/1e4CaQ5VUF3F04XRDGXrnRQGogo89TiF8/view?usp=sharing)，以下的code分別為下載和觀看這次的資料大概長甚麼樣子。\n",
        "\n",
        "特別注意一點: **這次的source和target data的圖片都是平衡的，你們可以使用這個資訊做其他事情。**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF-i0sVlnUbq",
        "outputId": "cc993a1c-eac0-462c-e9dc-bc03831c12e5"
      },
      "outputs": [],
      "source": [
        "# # Download dataset\n",
        "# !gdown --id '1e4CaQ5VUF3F04XRDGXrnRQGogo89TiF8' --output real_or_drawing.zip\n",
        "# # Unzip the files\n",
        "# !unzip real_or_drawing.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "0_uO-ZSDoR6i",
        "outputId": "d03a3f46-3233-47b7-d552-45ca947128ee"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def no_axis_show(img, title='', cmap=None):\n",
        "  # imshow, and set the interpolation mode to be \"nearest\"。\n",
        "  # fig = plt.imshow(img, interpolation='nearest', cmap=cmap)\n",
        "  fig = plt.imshow(img, interpolation='bicubic', cmap=cmap)\n",
        "  # do not show the axis in the images.\n",
        "  fig.axes.get_xaxis().set_visible(False)\n",
        "  fig.axes.get_yaxis().set_visible(False)\n",
        "  plt.title(title)\n",
        "\n",
        "titles = ['horse', 'bed', 'clock', 'apple', 'cat', 'plane', 'television', 'dog', 'dolphin', 'spider']\n",
        "plt.figure(figsize=(18, 18))\n",
        "for i in range(10):\n",
        "  plt.subplot(1, 10, i+1)\n",
        "  fig = no_axis_show(plt.imread(f'./real_or_drawing/train_data/{i}/{500*i}.bmp'), title=titles[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "3eMs7DbVt4Ee",
        "outputId": "cd510834-6036-4670-be2c-0b537b4fcdad"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18, 18))\n",
        "for i in range(10):\n",
        "  plt.subplot(1, 10, i+1)\n",
        "  fig = no_axis_show(plt.imread(f'./real_or_drawing/test_data/0/' + str(i).rjust(5, '0') + '.bmp'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "moXQw9To5TqZ"
      },
      "source": [
        "# Special Domain Knowledge\n",
        "\n",
        "因為大家塗鴉的時候通常只會畫輪廓，我們可以根據這點將source data做點邊緣偵測處理，讓source data更像target data一點。\n",
        "\n",
        "## Canny Edge Detection\n",
        "算法這邊不贅述，只教大家怎麼用。若有興趣歡迎參考wiki或[這裡](https://medium.com/@pomelyu5199/canny-edge-detector-%E5%AF%A6%E4%BD%9C-opencv-f7d1a0a57d19)。\n",
        "\n",
        "cv2.Canny使用非常方便，只需要兩個參數: low_threshold, high_threshold。\n",
        "\n",
        "```cv2.Canny(image, low_threshold, high_threshold)```\n",
        "\n",
        "簡單來說就是當邊緣值超過high_threshold，我們就確定它是edge。如果只有超過low_threshold，那就先判斷一下再決定是不是edge。\n",
        "\n",
        "以下我們直接拿source data做做看。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "mn2MkDLV7E2-",
        "outputId": "9204cbea-932b-4d19-f687-88b3d241f632"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "titles = ['horse', 'bed', 'clock', 'apple', 'cat', 'plane', 'television', 'dog', 'dolphin', 'spider']\n",
        "plt.figure(figsize=(18, 18))\n",
        "\n",
        "original_img = plt.imread(f'./real_or_drawing/train_data/0/0.bmp')\n",
        "plt.subplot(1, 5, 1)\n",
        "no_axis_show(original_img, title='original')\n",
        "\n",
        "gray_img = cv2.cvtColor(original_img, cv2.COLOR_RGB2GRAY)\n",
        "plt.subplot(1, 5, 2)\n",
        "no_axis_show(gray_img, title='gray scale', cmap='gray')\n",
        "\n",
        "canny_50100 = cv2.Canny(gray_img, 50, 100)\n",
        "plt.subplot(1, 5, 3)\n",
        "no_axis_show(canny_50100, title='Canny(50, 100)', cmap='gray')\n",
        "\n",
        "canny_150200 = cv2.Canny(gray_img, 150, 200)\n",
        "plt.subplot(1, 5, 4)\n",
        "no_axis_show(canny_150200, title='Canny(150, 200)', cmap='gray')\n",
        "\n",
        "canny_250300 = cv2.Canny(gray_img, 250, 300)\n",
        "plt.subplot(1, 5, 5)\n",
        "no_axis_show(canny_250300, title='Canny(250, 300)', cmap='gray')\n",
        "  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8THSdt_hmwYh"
      },
      "source": [
        "# Data Process\n",
        "\n",
        "在這裡我故意將data用成可以使用torchvision.ImageFolder的形式，所以只要使用該函式便可以做出一個datasets。\n",
        "\n",
        "transform的部分請參考以下註解。\n",
        "<!-- \n",
        "#### 一些細節\n",
        "\n",
        "在一般的版本上，對灰階圖片使用RandomRotation使用```transforms.RandomRotation(15)```即可。但在colab上需要加上```fill=(0,)```才可運行。\n",
        "在n98上執行需要把```fill=(0,)```拿掉才可運行。 -->\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZHIBGknmi8Z"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from time import time\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def same_seeds(seed):\n",
        "    # Python built-in random module\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Torch\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(1116)\n",
        "\n",
        "source_transform = transforms.Compose([\n",
        "    # Turn RGB to grayscale. (Bacause Canny do not support RGB images.)\n",
        "    transforms.Grayscale(),\n",
        "    # cv2 do not support skimage.Image, so we transform it to np.array, \n",
        "    # and then adopt cv2.Canny algorithm.\n",
        "    transforms.Lambda(lambda x: cv2.Canny(np.array(x), 170, 300)),\n",
        "    # Transform np.array back to the skimage.Image.\n",
        "    transforms.ToPILImage(),\n",
        "    # 50% Horizontal Flip. (For Augmentation)\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # Rotate +- 15 degrees. (For Augmentation), and filled with zero \n",
        "    # if there's empty pixel after rotation.\n",
        "    transforms.RandomRotation(15, fill=(0,)),\n",
        "    # Transform to tensor for model inputs.\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "target_transform = transforms.Compose([\n",
        "    # Turn RGB to grayscale.\n",
        "    transforms.Grayscale(),\n",
        "    # Resize: size of source data is 32x32, thus we need to \n",
        "    #  enlarge the size of target data from 28x28 to 32x32。\n",
        "    transforms.Resize((32, 32)),\n",
        "    # 50% Horizontal Flip. (For Augmentation)\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # Rotate +- 15 degrees. (For Augmentation), and filled with zero \n",
        "    # if there's empty pixel after rotation.\n",
        "    transforms.RandomRotation(15, fill=(0,)),\n",
        "    # Transform to tensor for model inputs.\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "source_dataset = ImageFolder('./real_or_drawing/train_data', transform=source_transform)\n",
        "target_dataset = ImageFolder('./real_or_drawing/test_data', transform=target_transform)\n",
        "\n",
        "source_dataloader = DataLoader(source_dataset, batch_size=32, shuffle=True)\n",
        "target_dataloader = DataLoader(target_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(target_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hdwDEMrOycs5"
      },
      "source": [
        "# Model\n",
        "\n",
        "Feature Extractor: 典型的VGG-like疊法。\n",
        "\n",
        "Label Predictor / Domain Classifier: MLP到尾。\n",
        "\n",
        "相信作業寫到這邊大家對以下的Layer都很熟悉，因此不再贅述。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uw2eP09z-pD"
      },
      "outputs": [],
      "source": [
        "class GradReverse(Function):\n",
        "    def __init__(self , lambd):\n",
        "        self.lambd = lambd\n",
        "        return\n",
        "\n",
        "    def forward(self , x):\n",
        "        return x.view_as(x)\n",
        "\n",
        "    def backward(self , grad_output):\n",
        "        return -self.lambd * grad_output\n",
        "\n",
        "def grad_reverse(x , lambd = 1.0):\n",
        "    return GradReverse(lambd)(x)\n",
        "    \n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(512, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(512, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(512, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x).squeeze()\n",
        "        return x\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(Classifier , self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(512 , 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.fc2 = nn.Linear(512 , 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.fc3 = nn.Linear(256 , 10)\n",
        "        # self.layer = nn.Sequential(\n",
        "        #     nn.Linear(512, 512),\n",
        "        #     nn.BatchNorm1d(512),\n",
        "        #     nn.ReLU(),\n",
        "\n",
        "        #     nn.Linear(512, 256),\n",
        "        #     nn.BatchNorm1d(256),\n",
        "        #     nn.ReLU(),\n",
        "\n",
        "        #     nn.Linear(256, 10),\n",
        "        # )\n",
        "\n",
        "    # def forward(self, h):\n",
        "    #     c = self.layer(h)\n",
        "    #     return c\n",
        "    def set_lambda(self , lambd):\n",
        "        self.lambd = lambd\n",
        "        return\n",
        "\n",
        "    def forward(self , x , reverse = False):\n",
        "        if (reverse):\n",
        "            x = grad_reverse(x , self.lambd)\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lxdBIPhF0Icb"
      },
      "source": [
        "# Pre-processing\n",
        "\n",
        "這裡我們選用Adam來當Optimizer。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrxKelBy0PJ7"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class_criterion = nn.CrossEntropyLoss()\n",
        "L1_loss = nn.L1Loss()\n",
        "def discrepancy(output_1 , output_2):\n",
        "\treturn torch.mean(torch.abs(F.softmax(output_1 , dim = 1) - F.softmax(output_2 , dim = 1)))\n",
        "\n",
        "\n",
        "generator = Generator().cuda()\n",
        "classifier_1 = Classifier().cuda()\n",
        "classifier_2 = Classifier().cuda()\n",
        "\n",
        "# generator.load_state_dict(torch.load(\"./MCDmodel/generator.pt\"))\n",
        "# classifier_1.load_state_dict(torch.load(\"./MCDmodel/classifier_1.pt\"))\n",
        "# classifier_2.load_state_dict(torch.load(\"./MCDmodel/classifier_2.pt\"))\n",
        "\n",
        "optimizer_generator = optim.Adam(generator.parameters())\n",
        "optimizer_classifier_1 = optim.Adam(classifier_1.parameters())\n",
        "optimizer_classifier_2 = optim.Adam(classifier_2.parameters())\n",
        "\n",
        "# batch_size = 128\n",
        "# learning_rate = 0.00002\n",
        "# weight_decay = 0.0005\n",
        "# epoch = 2000\n",
        "# (optimizer_generator , optimizer_classifier_1 , optimizer_classifier_2) = (Adam(generator.parameters() , lr = learning_rate , weight_decay = weight_decay) , Adam(classifier_1.parameters() , lr = learning_rate , weight_decay = weight_decay) , Adam(classifier_2.parameters() , lr = learning_rate , weight_decay = weight_decay))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xuAE4cqJ0itR"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## 如何實作DaNN?\n",
        "\n",
        "理論上，在原始paper中是加上Gradient Reversal Layer，並將Feature Extractor / Label Predictor / Domain Classifier 一起train，但其實我們也可以交換的train Domain Classfier & Feature Extractor(就像在train GAN的Generator & Discriminator一樣)，這也是可行的。\n",
        "\n",
        "在code實現中，我們採取後者的方式。\n",
        "\n",
        "## 小提醒\n",
        "* 原文中的lambda(控制Domain Adversarial Loss的係數)是有Adaptive的版本，如果有興趣可以參考[原文](https://arxiv.org/pdf/1505.07818.pdf)。\n",
        "* 因為我們完全沒有target的label，所以結果如何，只好丟kaggle看看囉:)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRAFFKvX0p9y",
        "outputId": "493d3566-991b-440a-c9e8-abf33cec7d49"
      },
      "outputs": [],
      "source": [
        "def MCD_train_epoch(epoch, num_epochs, source_dataloader, target_dataloader):\n",
        "    '''\n",
        "    Args:\n",
        "    source_dataloader: source data的dataloader\n",
        "    target_dataloader: target data的dataloader\n",
        "    lamb: control the balance of domain adaptatoin and classification.\n",
        "    '''\n",
        "    start = time()\n",
        "    # D loss: Domain Classifier的loss\n",
        "    # F loss: Feature Extrator & Label Predictor的loss\n",
        "    running_Step1_loss, running_Step2_loss, running_Step3_loss = 0.0, 0.0, 0.0\n",
        "    total_hit1, total_hit2, total_num = 0.0, 0.0, 0.0\n",
        "\n",
        "    # for i, ((source_data, source_label), (target_data, _)) in tqdm(enumerate(zip(source_dataloader, target_dataloader))):\n",
        "    for i, ((source_data, source_label), (target_data, _)) in enumerate(zip(source_dataloader, target_dataloader)):\n",
        "\n",
        "        source_data = source_data.cuda()\n",
        "        source_label = source_label.cuda()\n",
        "        target_data = target_data.cuda()\n",
        "\n",
        "        # Step 1\n",
        "        optimizer_generator.zero_grad()\n",
        "        optimizer_classifier_1.zero_grad()\n",
        "        optimizer_classifier_2.zero_grad()\n",
        "\n",
        "        feature = generator(source_data)\n",
        "        y_1 = classifier_1(feature)\n",
        "        y_2 = classifier_2(feature)\n",
        "        loss = class_criterion(y_1 , source_label) + class_criterion(y_2 , source_label)\n",
        "        running_Step1_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer_generator.step()\n",
        "        optimizer_classifier_1.step()\n",
        "        optimizer_classifier_2.step()\n",
        "\n",
        "        # Step 2\n",
        "        optimizer_generator.zero_grad()\n",
        "        optimizer_classifier_1.zero_grad()\n",
        "        optimizer_classifier_2.zero_grad()\n",
        "\n",
        "        feature = generator(source_data)\n",
        "        y_1 = classifier_1(feature)\n",
        "        y_2 = classifier_2(feature)\n",
        "        loss_1 = class_criterion(y_1 , source_label) + class_criterion(y_2 , source_label)\n",
        "\n",
        "        feature = generator(target_data)\n",
        "        y_1 = classifier_1(feature)\n",
        "        y_2 = classifier_2(feature)\n",
        "        loss_2 = discrepancy(y_1 , y_2)\n",
        "\n",
        "        loss = loss_1 - loss_2\n",
        "        running_Step2_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer_classifier_1.step()\n",
        "        optimizer_classifier_2.step()\n",
        "        \n",
        "        # Step 3\n",
        "        for k in range(4):\n",
        "            optimizer_generator.zero_grad()\n",
        "            feature = generator(target_data)\n",
        "            y_1 = classifier_1(feature)\n",
        "            y_2 = classifier_2(feature)\n",
        "            loss_discrepancy = discrepancy(y_1 , y_2)\n",
        "            if i == 3:\n",
        "                    running_Step3_loss += loss_discrepancy.item()\n",
        "\n",
        "            loss_discrepancy.backward()\n",
        "            \n",
        "            optimizer_generator.step()\n",
        "\n",
        "        if (i < min(len(source_dataloader) , len(target_dataloader)) - 1):\n",
        "            m = int(50 * (i + 1) / min(len(source_dataloader) , len(target_dataloader)))\n",
        "            bar = m * '=' + '>' + (49 - m) * ' '\n",
        "            print('epoch {}/{} [{}]'.format(epoch + 1 , num_epochs , bar) , end = '\\r')\n",
        "        else:\n",
        "            bar = 50 * '='\n",
        "            end = time()\n",
        "            print('epoch {}/{} [{}] ({}s)'.format(epoch+ 1 , num_epochs , bar , int(end - start)))\n",
        "\n",
        "\n",
        "        feature = generator(source_data)\n",
        "        y_1 = classifier_1(feature)\n",
        "        y_2 = classifier_2(feature)\n",
        "        total_hit1 += torch.sum(torch.argmax(y_1, dim=1) == source_label).item()\n",
        "        total_hit2 += torch.sum(torch.argmax(y_2, dim=1) == source_label).item()\n",
        "        total_num += source_data.shape[0]\n",
        "        # print(i, end='\\r')\n",
        "\n",
        "    return running_Step1_loss / (i+1) , running_Step2_loss / (i+1), running_Step3_loss / (i+1), total_hit1 / total_num, total_hit2 / total_num\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# training\n",
        "num_epochs = 2000\n",
        "\n",
        "# generator.load_state_dict(torch.load(\"./MCDmodel/generator.pt\"))\n",
        "# classifier_1.load_state_dict(torch.load(\"./MCDmodel/classifier_1.pt\"))\n",
        "# classifier_2.load_state_dict(torch.load(\"./MCDmodel/classifier_2.pt\"))\n",
        "\n",
        "generator.train()\n",
        "classifier_1.train()\n",
        "classifier_2.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # You should chooose lamnda cleverly.\n",
        "    # lamb = adaptive_lambda(epoch, num_epochs)\n",
        "    train_Step1_loss, train_Step2_loss, train_Discrepency_loss, trainF1_acc, trainF2_acc = MCD_train_epoch(epoch, num_epochs, source_dataloader, target_dataloader)\n",
        "\n",
        "    torch.save(generator.state_dict() , './MCDmodel/generator.pt')\n",
        "    torch.save(classifier_1.state_dict() , './MCDmodel/classifier_1.pt')\n",
        "    torch.save(classifier_2.state_dict() , './MCDmodel/classifier_2.pt')\n",
        "    print('epoch {:>3d}: train_Step1_loss: {:6.4f}, train_Step2_loss: {:6.4f}, train_Discrepency_loss: {:6.4f}, F1_acc {:6.4f}, F2_acc {:6.4f}'.format(epoch+1, train_Step1_loss, train_Step2_loss, train_Discrepency_loss, trainF1_acc, trainF2_acc))\n",
        "\n",
        "    if epoch != 0 and epoch % 100 == 0 :\n",
        "        result = []\n",
        "\n",
        "        generator.eval()\n",
        "        classifier_1.eval()\n",
        "        classifier_2.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, (test_data, _) in enumerate(test_dataloader):\n",
        "                test_data = test_data.cuda()\n",
        "\n",
        "                feature = generator(test_data)\n",
        "                y_1 = classifier_1(feature)\n",
        "                y_2 = classifier_2(feature)\n",
        "                y = (y_1 + y_2) \n",
        "                \n",
        "                answer = torch.argmax(y, dim = 1).cpu().detach().numpy()\n",
        "                result.append(answer)\n",
        "\n",
        "        import pandas as pd\n",
        "        result = np.concatenate(result)\n",
        "\n",
        "        # Generate your submission\n",
        "        df = pd.DataFrame({'id': np.arange(0,len(result)), 'label': result})\n",
        "        df.to_csv('./MCD_Predict/MCD_submission-'+str(epoch)+'.csv',index=False)\n",
        "\n",
        "        generator.train()\n",
        "        classifier_1.train()\n",
        "        classifier_2.train()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o8_-0iSSje4w"
      },
      "source": [
        "# Inference\n",
        "\n",
        "就跟前幾次作業一樣。這裡我使用pd來生產csv，因為看起來比較潮(?)\n",
        "\n",
        "此外，200 epochs的Accuracy可能會不太穩定，可以多丟幾次或train久一點。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wly5AgH2jePv"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "\n",
        "generator = Generator().cuda()\n",
        "classifier_1 = Classifier().cuda()\n",
        "classifier_2 = Classifier().cuda()\n",
        "\n",
        "generator.load_state_dict(torch.load(\"./MCDmodel/generator.pt\"))\n",
        "classifier_1.load_state_dict(torch.load(\"./MCDmodel/classifier_1.pt\"))\n",
        "classifier_2.load_state_dict(torch.load(\"./MCDmodel/classifier_2.pt\"))\n",
        "\n",
        "generator.eval()\n",
        "classifier_1.eval()\n",
        "classifier_2.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (test_data, _) in enumerate(test_dataloader):\n",
        "        test_data = test_data.cuda()\n",
        "\n",
        "        feature = generator(test_data)\n",
        "        y_1 = classifier_1(feature)\n",
        "        y_2 = classifier_2(feature)\n",
        "        y = (y_1 + y_2) \n",
        "        \n",
        "        answer = torch.argmax(y, dim = 1).cpu().detach().numpy()\n",
        "        result.append(answer)\n",
        "\n",
        "import pandas as pd\n",
        "result = np.concatenate(result)\n",
        "\n",
        "# Generate your submission\n",
        "df = pd.DataFrame({'id': np.arange(0,len(result)), 'label': result})\n",
        "df.to_csv('MCD_submission.csv',index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtXnEMUNCE78"
      },
      "source": [
        "# Training Statistics\n",
        "\n",
        "- Number of parameters:\n",
        "  - Feature Extractor: 2, 142, 336\n",
        "  - Label Predictor: 530, 442\n",
        "  - Domain Classifier: 1, 055, 233\n",
        "\n",
        "- Simple\n",
        " - Training time on colab: ~ 1 hr\n",
        "- Medium\n",
        " - Training time on colab: 2 ~ 4 hr\n",
        "- Strong\n",
        " - Training time on colab: 5 ~ 6 hrs\n",
        "- Boss\n",
        " - **Unmeasurable**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "duk7k43Am9xH"
      },
      "source": [
        "# Learning Curve (Strong Baseline)\n",
        "* This method is slightly different from colab.\n",
        "\n",
        "![Loss Curve](https://i.imgur.com/vIujQyo.png)\n",
        "\n",
        "# Accuracy Curve (Strong Baseline)\n",
        "* Note that you cannot access testing accuracy. But this plot tells you that even though the model overfits the training data, the testing accuracy is still improving, and that's why you need to train more epochs.\n",
        "\n",
        "![Acc Curve](https://i.imgur.com/4W1otXG.png)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s6UfXzef-wNl"
      },
      "source": [
        "# Special Thanks\n",
        "下面是原本台大助教提供的參考作業。\n",
        "\n",
        "[NTU_r08942071_太神啦 / 組長: 劉正仁同學](https://drive.google.com/open?id=11uNDcz7_eMS8dMQxvnWsbrdguu9k4c-c)\n",
        "\n",
        "[NTU_r08921a08_CAT / 組長: 廖子毅同學](https://drive.google.com/open?id=1xIkSs8HAShdcfV1E0NEnf4JDbL7POZTf)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
