{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mz0_QVkxCrX3"},"source":["# **Homework 1: COVID-19 Cases Prediction (Regression)**"]},{"cell_type":"markdown","metadata":{"id":"ZeZnPAiwDRWG"},"source":["Author: Heng-Jui Chang\n","\n","Objectives:\n","* Solve a regression problem with deep neural networks (DNN).\n","* Understand basic DNN training tips.\n","* Get familiar with PyTorch.\n","\n","If any questions, please contact the TAs via TA hours, or email.\n"]},{"cell_type":"markdown","metadata":{"id":"Jx3x1nDkG-Uy"},"source":["# **Download Data**\n","\n","\n","If the Google drive links are dead, you can download data from [kaggle](https://www.kaggle.com/c/ntpucsie-ml2022spring-hw1-v2), and upload data manually to the workspace.\n","\n","如果需要邀請，邀請連結，這是[邀請連結](https://www.kaggle.com/t/7d7a965ceab54a46b9ec76973c25149a)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMj55YDKG6ch","outputId":"5622eee0-40ea-4167-d4d4-9c88eca2bc9c","executionInfo":{"status":"ok","timestamp":1678797354985,"user_tz":-480,"elapsed":4479,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["tr_path = 'covid.train_v2.csv'  # path to training data\n","tt_path = 'covid.test_v2.csv'   # path to testing data\n","\n","!gdown --id '1Wweg6vyFs2GbLzbi4CLA64cWb1gQafPA' --output covid.train_v2.csv\n","!gdown --id '1VtQ8E3cy6gatnYPkJZ7f4BkLA7BmQhyd' --output covid.test_v2.csv"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.9/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1Wweg6vyFs2GbLzbi4CLA64cWb1gQafPA\n","To: /content/covid.train_v2.csv\n","100% 1.58M/1.58M [00:00<00:00, 163MB/s]\n","/usr/local/lib/python3.9/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1VtQ8E3cy6gatnYPkJZ7f4BkLA7BmQhyd\n","To: /content/covid.test_v2.csv\n","100% 408k/408k [00:00<00:00, 121MB/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"wS_4-77xHk44"},"source":["# **Import Some Packages**"]},{"cell_type":"code","metadata":{"id":"k-onQd4JNA5H","executionInfo":{"status":"ok","timestamp":1678797361344,"user_tz":-480,"elapsed":6366,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["# PyTorch\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","# For data preprocess\n","import numpy as np\n","import csv\n","import os\n","\n","# For plotting\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","\n","myseed = 42069  # set a random seed for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BtE3b6JEH7rw"},"source":["# **Some Utilities**\n","\n","You do not need to modify this part."]},{"cell_type":"code","metadata":{"id":"FWMT3uf1NGQp","executionInfo":{"status":"ok","timestamp":1678797361345,"user_tz":-480,"elapsed":5,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["def get_device():\n","    ''' Get device (if GPU is available, use GPU) '''\n","    return 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","def plot_learning_curve(loss_record, title=''):\n","    ''' Plot learning curve of your DNN (train & dev loss) '''\n","    total_steps = len(loss_record['train'])\n","    x_1 = range(total_steps)\n","    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n","    figure(figsize=(6, 4))\n","    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n","    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n","    plt.ylim(0.0, 5.)\n","    plt.xlabel('Training steps')\n","    plt.ylabel('MSE loss')\n","    plt.title('Learning curve of {}'.format(title))\n","    plt.legend()\n","    plt.show()\n","\n","\n","def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n","    ''' Plot prediction of your DNN '''\n","    if preds is None or targets is None:\n","        model.eval()\n","        preds, targets = [], []\n","        for x, y in dv_set:\n","            x, y = x.to(device), y.to(device)\n","            with torch.no_grad():\n","                pred = model(x)\n","                preds.append(pred.detach().cpu())\n","                targets.append(y.detach().cpu())\n","        preds = torch.cat(preds, dim=0).numpy()\n","        targets = torch.cat(targets, dim=0).numpy()\n","\n","    figure(figsize=(5, 5))\n","    plt.scatter(targets, preds, c='r', alpha=0.5)\n","    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n","    plt.xlim(-0.2, lim)\n","    plt.ylim(-0.2, lim)\n","    plt.xlabel('ground truth value')\n","    plt.ylabel('predicted value')\n","    plt.title('Ground Truth v.s. Prediction')\n","    plt.show()"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"39U_XFX6KOoj"},"source":["# **Preprocess**\n","\n","We have three kinds of datasets:\n","* `train`: for training\n","* `dev`: for validation\n","* `test`: for testing (w/o target value)"]},{"cell_type":"markdown","metadata":{"id":"TQ-MdwpLL7Dt"},"source":["## **Dataset**\n","\n","The `COVID19Dataset` below does:\n","* read `.csv` files\n","* extract features\n","* split `covid.train.csv` into train/dev sets\n","* normalize features\n","\n","Finishing `TODO` below might make you pass medium baseline."]},{"cell_type":"code","metadata":{"id":"0zlpIp9ANJRU","executionInfo":{"status":"ok","timestamp":1678797361345,"user_tz":-480,"elapsed":5,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["class COVID19Dataset(Dataset):\n","    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n","    def __init__(self,\n","                 path,\n","                 mode='train',\n","                 target_only=False):\n","        self.mode = mode\n","\n","        # Read data into numpy arrays\n","        with open(path, 'r') as fp:\n","            data = list(csv.reader(fp))\n","            data = np.array(data[1:])[:, 1:].astype(float)\n","        \n","        if not target_only:\n","            feats = list(range(93))\n","        else:\n","            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n","            # feats = list(range(1, 41)) + [57, 75]\n","            # feats = [75, 57, 42, 60, 78, 43, 61, 79, 40, 58, 76, 41, 59, 77] #上面挑选的最优特征\n","            pass\n","\n","        if mode == 'test':\n","            # Testing data\n","            # data: 560 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n","            data = data[:, feats]\n","            self.data = torch.FloatTensor(data)\n","        else:\n","            # Training data (train/dev sets)\n","            # data: 2140 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n","            target = data[:, -1]\n","            data = data[:, feats]\n","            \n","            # Splitting training data into train & dev sets\n","            if mode == 'train':\n","                #indices = [i for i in range(len(data)) if i % 10 != 0]\n","                indices = [i for i in range(len(data))]\n","            elif mode == 'dev':\n","                #indices = [i for i in range(len(data)) if i % 10 == 0]\n","                indices = [i for i in range(len(data))]\n","            \n","            # Convert data into PyTorch tensors\n","            self.data = torch.FloatTensor(data[indices])\n","            self.target = torch.FloatTensor(target[indices])\n","\n","        # Normalize features (you may remove this part to see what will happen)\n","        self.data[:, 40:] = \\\n","            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n","            / self.data[:, 40:].std(dim=0, keepdim=True)\n","\n","        self.dim = self.data.shape[1]\n","\n","        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n","              .format(mode, len(self.data), self.dim))\n","\n","    def __getitem__(self, index):\n","        # Returns one sample at a time\n","        if self.mode in ['train', 'dev']:\n","            # For training\n","            return self.data[index], self.target[index]\n","        else:\n","            # For testing (no target)\n","            return self.data[index]\n","\n","    def __len__(self):\n","        # Returns the size of the dataset\n","        return len(self.data)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AlhTlkE7MDo3"},"source":["## **DataLoader**\n","\n","A `DataLoader` loads data from a given `Dataset` into batches.\n"]},{"cell_type":"code","metadata":{"id":"hlhLk5t6MBX3","executionInfo":{"status":"ok","timestamp":1678797361345,"user_tz":-480,"elapsed":5,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n","    ''' Generates a dataset, then is put into a dataloader. '''\n","    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n","    dataloader = DataLoader(\n","        dataset, batch_size,\n","        shuffle=(mode == 'train'), drop_last=False,\n","        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n","    return dataloader"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SGuycwR0MeQB"},"source":["# **Deep Neural Network**\n","\n","`NeuralNet` is an `nn.Module` designed for regression.\n","The DNN consists of 2 fully-connected layers with ReLU activation.\n","This module also included a function `cal_loss` for calculating loss.\n"]},{"cell_type":"code","metadata":{"id":"49-uXYovOAI0","executionInfo":{"status":"ok","timestamp":1678797361346,"user_tz":-480,"elapsed":6,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["class NeuralNet(nn.Module):\n","    ''' A simple fully-connected deep neural network '''\n","    def __init__(self, input_dim):\n","        super(NeuralNet, self).__init__()\n","\n","        # Define your neural network here\n","        # TODO: How to modify this model to achieve better performance?\n","        self.net = nn.Sequential(\n","            # nn.Linear(input_dim, 64),\n","            # nn.ReLU(),\n","            # nn.Linear(64, 1)\n","            nn.Linear(input_dim, 32),\n","            nn.BatchNorm1d(32),\n","            nn.Dropout(p=0.2),\n","            nn.LeakyReLU(),\n","            nn.Linear(32, 1)\n","        )\n","\n","        # Mean squared error loss\n","        self.criterion = nn.MSELoss(reduction='mean')\n","\n","    def forward(self, x):\n","        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n","        return self.net(x).squeeze(1)\n","\n","    def cal_loss(self, pred, target):\n","        ''' Calculate loss '''\n","        # TODO: you may implement L1/L2 regularization here\n","        return self.criterion(pred, target)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DvFWVjZ5Nvga"},"source":["# **Train/Dev/Test**"]},{"cell_type":"markdown","metadata":{"id":"MAM8QecJOyqn"},"source":["## **Training**"]},{"cell_type":"code","metadata":{"id":"lOqcmYzMO7jB","executionInfo":{"status":"ok","timestamp":1678797361346,"user_tz":-480,"elapsed":5,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["def train(tr_set, dv_set, model, config, device):\n","    ''' DNN training '''\n","\n","    n_epochs = config['n_epochs']  # Maximum number of epochs\n","\n","    # Setup optimizer\n","    optimizer = getattr(torch.optim, config['optimizer'])(\n","        model.parameters(), **config['optim_hparas'])\n","\n","    min_mse = 1000.\n","    loss_record = {'train': [], 'dev': []}      # for recording training loss\n","    early_stop_cnt = 0\n","    epoch = 0\n","    while epoch < n_epochs:\n","        model.train()                           # set model to training mode\n","        for x, y in tr_set:                     # iterate through the dataloader\n","            optimizer.zero_grad()               # set gradient to zero\n","            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n","            pred = model(x)                     # forward pass (compute output)\n","            mse_loss = model.cal_loss(pred, y)  # compute loss\n","            mse_loss.backward()                 # compute gradient (backpropagation)\n","            optimizer.step()                    # update model with optimizer\n","            loss_record['train'].append(mse_loss.detach().cpu().item())\n","\n","        # After each epoch, test your model on the validation (development) set.\n","        dev_mse = dev(dv_set, model, device)\n","        if dev_mse < min_mse:\n","            # Save model if your model improved\n","            min_mse = dev_mse\n","            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n","                .format(epoch + 1, min_mse))\n","            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n","            early_stop_cnt = 0\n","        else:\n","            early_stop_cnt += 1\n","\n","        epoch += 1\n","        loss_record['dev'].append(dev_mse)\n","        if early_stop_cnt > config['early_stop']:\n","            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n","            break\n","\n","    print('Finished training after {} epochs'.format(epoch))\n","    return min_mse, loss_record"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0hSd4Bn3O2PL"},"source":["## **Validation**"]},{"cell_type":"code","metadata":{"id":"yrxrD3YsN3U2","executionInfo":{"status":"ok","timestamp":1678797361346,"user_tz":-480,"elapsed":5,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["def dev(dv_set, model, device):\n","    model.eval()                                # set model to evalutation mode\n","    total_loss = 0\n","    for x, y in dv_set:                         # iterate through the dataloader\n","        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n","        with torch.no_grad():                   # disable gradient calculation\n","            pred = model(x)                     # forward pass (compute output)\n","            mse_loss = model.cal_loss(pred, y)  # compute loss\n","        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n","    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n","\n","    return total_loss"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g0pdrhQAO41L"},"source":["## **Testing**"]},{"cell_type":"code","metadata":{"id":"aSBMRFlYN5tB","executionInfo":{"status":"ok","timestamp":1678797361346,"user_tz":-480,"elapsed":5,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["def test(tt_set, model, device):\n","    model.eval()                                # set model to evalutation mode\n","    preds = []\n","    for x in tt_set:                            # iterate through the dataloader\n","        x = x.to(device)                        # move data to device (cpu/cuda)\n","        with torch.no_grad():                   # disable gradient calculation\n","            pred = model(x)                     # forward pass (compute output)\n","            preds.append(pred.detach().cpu())   # collect prediction\n","    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n","    return preds"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SvckkF5dvf0j"},"source":["# **Setup Hyper-parameters**\n","\n","`config` contains hyper-parameters for training and the path to save your model."]},{"cell_type":"code","metadata":{"id":"NPXpdumwPjE7","executionInfo":{"status":"ok","timestamp":1678797361347,"user_tz":-480,"elapsed":6,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["device = get_device()                 # get the current available device ('cpu' or 'cuda')\n","os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n","# target_only = False                   # TODO: Using 40 states & 2 tested_positive features\n","target_only = True        \n","\n","# TODO: How to tune these hyper-parameters to improve your model's performance?\n","# config = {\n","#     'n_epochs': 3000,                # maximum number of epochs\n","#     'batch_size': 270,               # mini-batch size for dataloader\n","#     'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n","#     'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n","#         'lr': 0.001,                 # learning rate of SGD\n","#         'momentum': 0.9              # momentum for SGD\n","#     },\n","#     'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n","#     'save_path': 'models/model.pth'  # your model will be saved here\n","# }\n","config = {\n","    'n_epochs': 10000,                # 因为有early_stop，所以大一点没有影响\n","    'batch_size': 200,               # 微调batchsize\n","    'optimizer': 'Adam',              # 使用Adam优化器\n","    'optim_hparas': {                # 完全使用默认参数\n","        #'lr': 0.0001,                 \n","        #'momentum': 0.9,             \n","        #'weight_decay': 5e-4,\n","    },\n","    'early_stop': 500,               # 由于最后训练使用了所有数据，大一点影响不大\n","    'save_path': 'models/model.pth'  \n","}"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6j1eOV3TOH-j"},"source":["# **Load data and model**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"eNrYBMmePLKm","outputId":"b0881b8e-fa08-454d-bce8-bf1a4308b417","executionInfo":{"status":"error","timestamp":1678797361779,"user_tz":-480,"elapsed":437,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n","dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)\n","tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], target_only=target_only)"],"execution_count":11,"outputs":[{"output_type":"error","ename":"UnboundLocalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-a81455a69d6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdv_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtt_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-2100559c27a5>\u001b[0m in \u001b[0;36mprep_dataloader\u001b[0;34m(path, mode, batch_size, n_jobs, target_only)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprep_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m''' Generates a dataset, then is put into a dataloader. '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOVID19Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_only\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Construct dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     dataloader = DataLoader(\n\u001b[1;32m      5\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-a58107f6ebb3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, target_only)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# data: 2140 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Splitting training data into train & dev sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'feats' referenced before assignment"]}]},{"cell_type":"code","metadata":{"id":"FHylSirLP9oh","executionInfo":{"status":"aborted","timestamp":1678797361779,"user_tz":-480,"elapsed":4,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sX2B_zgSOPTJ"},"source":["# **Start Training!**"]},{"cell_type":"code","metadata":{"id":"GrEbUxazQAAZ","executionInfo":{"status":"aborted","timestamp":1678797361780,"user_tz":-480,"elapsed":5,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hsNO9nnXQBvP","executionInfo":{"status":"aborted","timestamp":1678797361780,"user_tz":-480,"elapsed":4,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["plot_learning_curve(model_loss_record, title='deep model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3iZTVn5WQFpX","executionInfo":{"status":"aborted","timestamp":1678797361780,"user_tz":-480,"elapsed":4,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["del model\n","model = NeuralNet(tr_set.dataset.dim).to(device)\n","ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n","model.load_state_dict(ckpt)\n","plot_pred(dv_set, model, device)  # Show prediction on the validation set"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aQikz3IPiyPf"},"source":["# **Testing**\n","The predictions of your model on testing set will be stored at `pred.csv`."]},{"cell_type":"code","metadata":{"id":"O8cTuQjQQOon","executionInfo":{"status":"aborted","timestamp":1678797361780,"user_tz":-480,"elapsed":4,"user":{"displayName":"Willy Chiu","userId":"13279626010263908651"}}},"source":["def save_pred(preds, file):\n","    ''' Save predictions to specified file '''\n","    print('Saving results to {}'.format(file))\n","    with open(file, 'w') as fp:\n","        writer = csv.writer(fp)\n","        writer.writerow(['id', 'tested_positive'])\n","        for i, p in enumerate(preds):\n","            writer.writerow([i, p])\n","\n","preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n","save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nfrVxqJanGpE"},"source":["# **Hints**\n","\n","## **Simple Baseline**\n","* Run sample code\n","\n","## **Medium Baseline**\n","* Feature selection: 40 states + 2 `tested_positive` (`TODO` in dataset)\n","* 注意註解，或許可以發現隱藏在code裡的bug。\n","\n","## **Strong Baseline**\n","* Feature selection (what other features are useful?)\n","* DNN architecture (layers? dimension? activation function?)\n","* Training (mini-batch? optimizer? learning rate?)\n","* L2 regularization\n","* There are some mistakes in the sample code, can you find them?"]},{"cell_type":"markdown","metadata":{"id":"9tmCwXgpot3t"},"source":["# **Reference**\n","This code is completely written by Heng-Jui Chang @ NTUEE.  \n","Copying or reusing this code is required to specify the original author. \n","\n","E.g.  \n","Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)\n"]}]}