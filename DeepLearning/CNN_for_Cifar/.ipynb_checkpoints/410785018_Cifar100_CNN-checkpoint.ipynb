{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2949c89c",
   "metadata": {},
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002a1e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from os.path import join\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba92278",
   "metadata": {},
   "source": [
    "# Read file and Img Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d069fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 32, 32, 3)\n",
      "(15000,)\n",
      "(15000, 32, 32, 3)\n",
      "(15000, 30)\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "traindata_path = r\"C:\\Users\\foo\\Desktop\\CNN\\Training_data\"\n",
    "\n",
    "numbers_of_traindata = 0\n",
    "numbers_of_testdata = 0\n",
    "\n",
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "label_folder = []\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "for root, dirts, files in os.walk(traindata_path):\n",
    "    for dirt in dirts:\n",
    "        label_folder.append(dirt)\n",
    "    numbers_of_traindata += len(files)\n",
    "    \n",
    "for i in range(len(label_folder)):\n",
    "    label_path = traindata_path + r\"\\\\\" + label_folder[i]\n",
    "    trainfileName = [f for f in listdir(label_path) if isfile(join(label_path, f))]\n",
    "    \n",
    "    for j in range(len(trainfileName)):\n",
    "        path2 = label_path + r\"\\\\\" + trainfileName[j]\n",
    "        img = cv2.imread(path2, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        # original\n",
    "        train_data.append(img)\n",
    "        train_label.append(label_folder[i])\n",
    "        \n",
    "\n",
    "print(np.array(train_data).shape)\n",
    "print(np.array(train_label).shape)\n",
    "\n",
    "########################################################################################\n",
    "#Convert a category vector to a binary (0 or 1) matrix-type representation\n",
    "\n",
    "train_label = to_categorical(train_label)\n",
    "\n",
    "print(np.array(train_data).shape)\n",
    "print(np.array(train_label).shape)\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "# normalization\n",
    "train_data = np.array(train_data).astype('float32')\n",
    "\n",
    "train_data,val_data,train_label,val_label = train_test_split(train_data, train_label, test_size = 0.1, random_state = 42)\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255, \n",
    "                                 #rotation_range = 15, \n",
    "                                 width_shift_range = 0.2, \n",
    "                                 height_shift_range = 0.2,\n",
    "                                 shear_range = 0.2,\n",
    "                                 zoom_range = 0.2\n",
    "                                 )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen.fit(train_data)\n",
    "val_datagen.fit(val_data)\n",
    "\n",
    "\n",
    "LR_function = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                patience = 2,\n",
    "                                verbose = 1,\n",
    "                                factor = 0.5,\n",
    "                                min_lr = 0.00001)\n",
    "\n",
    "EarlyStop = EarlyStopping(monitor='val_loss',\n",
    "                          patience = 6,\n",
    "                          verbose = 1, \n",
    "                          mode = 'min')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89e25e",
   "metadata": {},
   "source": [
    "# Load Keras Data and Img Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8485d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 100)\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_label), (test_data, test_label) = keras.datasets.cifar100.load_data()\n",
    "train_data.reshape(50000, 32, 32, 3)\n",
    "test_data.reshape(10000, 32, 32, 3)\n",
    "\n",
    "train_label = to_categorical(train_label, 100)\n",
    "test_label = to_categorical(test_label, 100)\n",
    "\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255, \n",
    "                                 #rotation_range = 15, \n",
    "                                 width_shift_range = 0.2, \n",
    "                                 height_shift_range = 0.2,\n",
    "                                 shear_range = 0.2,\n",
    "                                 zoom_range = 0.2\n",
    "                                 )\n",
    "\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen.fit(train_data)\n",
    "test_datagen.fit(test_data)\n",
    "\n",
    "LR_function = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                patience = 2,\n",
    "                                verbose = 1,\n",
    "                                factor = 0.5,\n",
    "                                min_lr = 0.00001)\n",
    "\n",
    "EarlyStop = EarlyStopping(monitor='val_loss',\n",
    "                          patience = 6,\n",
    "                          verbose = 1, \n",
    "                          mode = 'min')\n",
    "\n",
    "print(np.array(train_data).shape)\n",
    "print(np.array(train_label).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8477587",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f0d7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 128)       3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                7710      \n",
      "=================================================================\n",
      "Total params: 6,662,046\n",
      "Trainable params: 6,655,902\n",
      "Non-trainable params: 6,144\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "# model \n",
    "model = Sequential()\n",
    "\n",
    "#conv1\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv2\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling1\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv3\n",
    "model.add(Conv2D(128,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv4\n",
    "model.add(Conv2D(128,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling2\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv5\n",
    "model.add(Conv2D(256,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv6\n",
    "model.add(Conv2D(256,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv7\n",
    "model.add(Conv2D(256,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling3\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv8\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv9\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling4\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(256, kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(128, kernel_initializer=\"he_normal\", activation=\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "# model.add(Dense(64, kernel_initializer=\"he_normal\", activation=\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(30, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a3c6ba",
   "metadata": {},
   "source": [
    "# Model - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "988cd094",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   1/1562 [..............................] - ETA: 0s - loss: 5.6144 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.0269s). Check your callbacks.\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 4.4067 - accuracy: 0.0511 - val_loss: 3.9101 - val_accuracy: 0.0927\n",
      "Epoch 2/50\n",
      "1562/1562 [==============================] - 70s 45ms/step - loss: 3.9264 - accuracy: 0.0896 - val_loss: 3.8974 - val_accuracy: 0.1162\n",
      "Epoch 3/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 3.5609 - accuracy: 0.1381 - val_loss: 3.7024 - val_accuracy: 0.1472\n",
      "Epoch 4/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 3.2812 - accuracy: 0.1823 - val_loss: 2.9709 - val_accuracy: 0.2439\n",
      "Epoch 5/50\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 3.0273 - accuracy: 0.2255 - val_loss: 2.8113 - val_accuracy: 0.2673\n",
      "Epoch 6/50\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 2.8064 - accuracy: 0.2680 - val_loss: 2.5160 - val_accuracy: 0.3267\n",
      "Epoch 7/50\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 2.6321 - accuracy: 0.3098 - val_loss: 2.6322 - val_accuracy: 0.3395\n",
      "Epoch 8/50\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 2.4878 - accuracy: 0.3413 - val_loss: 2.2583 - val_accuracy: 0.3922\n",
      "Epoch 9/50\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 2.3563 - accuracy: 0.3712 - val_loss: 2.1336 - val_accuracy: 0.4232\n",
      "Epoch 10/50\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 2.2387 - accuracy: 0.3971 - val_loss: 2.1819 - val_accuracy: 0.4205\n",
      "Epoch 11/50\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 2.1483 - accuracy: 0.4217 - val_loss: 2.0681 - val_accuracy: 0.4543\n",
      "Epoch 12/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 2.0583 - accuracy: 0.4440 - val_loss: 1.9056 - val_accuracy: 0.4819\n",
      "Epoch 13/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.9860 - accuracy: 0.4576 - val_loss: 2.0229 - val_accuracy: 0.4730\n",
      "Epoch 14/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.9256 - accuracy: 0.4776 - val_loss: 1.9014 - val_accuracy: 0.4986\n",
      "Epoch 15/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.8565 - accuracy: 0.4943 - val_loss: 1.8300 - val_accuracy: 0.5096\n",
      "Epoch 16/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.8019 - accuracy: 0.5098 - val_loss: 1.7450 - val_accuracy: 0.5240\n",
      "Epoch 17/50\n",
      "1562/1562 [==============================] - 72s 46ms/step - loss: 1.7440 - accuracy: 0.5196 - val_loss: 1.7854 - val_accuracy: 0.5257\n",
      "Epoch 18/50\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.7044 - accuracy: 0.5318\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.7045 - accuracy: 0.5318 - val_loss: 1.7870 - val_accuracy: 0.5236\n",
      "Epoch 19/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.5296 - accuracy: 0.5711 - val_loss: 1.6835 - val_accuracy: 0.5492\n",
      "Epoch 20/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.4702 - accuracy: 0.5840 - val_loss: 1.5476 - val_accuracy: 0.5775\n",
      "Epoch 21/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.4282 - accuracy: 0.5976 - val_loss: 1.5453 - val_accuracy: 0.5844\n",
      "Epoch 22/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.3885 - accuracy: 0.6089 - val_loss: 1.6200 - val_accuracy: 0.5699\n",
      "Epoch 23/50\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.3676 - accuracy: 0.6118\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.3678 - accuracy: 0.6118 - val_loss: 1.5506 - val_accuracy: 0.5853\n",
      "Epoch 24/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.2736 - accuracy: 0.6360 - val_loss: 1.5050 - val_accuracy: 0.6008\n",
      "Epoch 25/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.2430 - accuracy: 0.6443 - val_loss: 1.5195 - val_accuracy: 0.6003\n",
      "Epoch 26/50\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.2224 - accuracy: 0.6493\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 1.2226 - accuracy: 0.6492 - val_loss: 1.5176 - val_accuracy: 0.5975\n",
      "Epoch 27/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.1749 - accuracy: 0.6606 - val_loss: 1.4655 - val_accuracy: 0.6095\n",
      "Epoch 28/50\n",
      "1562/1562 [==============================] - 71s 45ms/step - loss: 1.1550 - accuracy: 0.6676 - val_loss: 1.4846 - val_accuracy: 0.6104\n",
      "Epoch 29/50\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.1472 - accuracy: 0.6683\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.1471 - accuracy: 0.6684 - val_loss: 1.5008 - val_accuracy: 0.6048\n",
      "Epoch 30/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.1124 - accuracy: 0.6764 - val_loss: 1.4635 - val_accuracy: 0.6136\n",
      "Epoch 31/50\n",
      "1562/1562 [==============================] - 70s 45ms/step - loss: 1.0992 - accuracy: 0.6777 - val_loss: 1.4713 - val_accuracy: 0.6115\n",
      "Epoch 32/50\n",
      "1562/1562 [==============================] - 72s 46ms/step - loss: 1.0984 - accuracy: 0.6780 - val_loss: 1.4476 - val_accuracy: 0.6186\n",
      "Epoch 33/50\n",
      "1562/1562 [==============================] - 70s 45ms/step - loss: 1.0789 - accuracy: 0.6859 - val_loss: 1.4595 - val_accuracy: 0.6168\n",
      "Epoch 34/50\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.0809 - accuracy: 0.6842\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 1.0811 - accuracy: 0.6842 - val_loss: 1.4640 - val_accuracy: 0.6156\n",
      "Epoch 35/50\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 1.0749 - accuracy: 0.6865 - val_loss: 1.4476 - val_accuracy: 0.6185\n",
      "Epoch 36/50\n",
      "1562/1562 [==============================] - ETA: 0s - loss: 1.0674 - accuracy: 0.6868\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.0674 - accuracy: 0.6868 - val_loss: 1.4562 - val_accuracy: 0.6175\n",
      "Epoch 37/50\n",
      "1562/1562 [==============================] - 70s 45ms/step - loss: 1.0640 - accuracy: 0.6893 - val_loss: 1.4587 - val_accuracy: 0.6201\n",
      "Epoch 38/50\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.0545 - accuracy: 0.6897\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.0542 - accuracy: 0.6898 - val_loss: 1.4503 - val_accuracy: 0.6195\n",
      "Epoch 39/50\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 1.0584 - accuracy: 0.6892 - val_loss: 1.4630 - val_accuracy: 0.6181\n",
      "Epoch 40/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.0524 - accuracy: 0.6935 - val_loss: 1.4496 - val_accuracy: 0.6194\n",
      "Epoch 41/50\n",
      "1562/1562 [==============================] - 69s 44ms/step - loss: 1.0452 - accuracy: 0.6944 - val_loss: 1.4610 - val_accuracy: 0.6193\n",
      "Epoch 00041: early stopping\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "# model \n",
    "model = Sequential()\n",
    "\n",
    "#conv1\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv2\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling1\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv3\n",
    "model.add(Conv2D(128,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv4\n",
    "model.add(Conv2D(128,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling2\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv5\n",
    "model.add(Conv2D(256,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv6\n",
    "model.add(Conv2D(256,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv7\n",
    "model.add(Conv2D(256,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling3\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv8\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv9\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling4\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv11\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv12\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv13\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling5\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec9b574",
   "metadata": {},
   "source": [
    "# Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13dd6843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30)                7710      \n",
      "=================================================================\n",
      "Total params: 8,246,110\n",
      "Trainable params: 8,239,710\n",
      "Non-trainable params: 6,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "# model \n",
    "model = Sequential()\n",
    "\n",
    "#conv1\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv2\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling1\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv3\n",
    "model.add(Conv2D(128,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv4\n",
    "model.add(Conv2D(128,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling2\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv5\n",
    "model.add(Conv2D(256,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv6\n",
    "model.add(Conv2D(256,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv7\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling3\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv8\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv9\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling4\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(256, kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(30, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d311b2",
   "metadata": {},
   "source": [
    "# Model - 4 (Best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e56f18b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 128)       3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 11,107,556\n",
      "Trainable params: 11,099,876\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "# model \n",
    "model = Sequential()\n",
    "\n",
    "#conv1\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv2\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling1\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv3\n",
    "model.add(Conv2D(256,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv4\n",
    "model.add(Conv2D(256,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling2\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv5\n",
    "model.add(Conv2D(256,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv6\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv7\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling3\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#conv8\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#conv9\n",
    "model.add(Conv2D(512,(3,3), padding=\"same\", kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#pooling4\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(256, kernel_initializer=\"he_normal\", activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "# model.add(Dense(30, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7379db7e",
   "metadata": {},
   "source": [
    "# Evaluation_For_LoadingKerasData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae278f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   1/1562 [..............................] - ETA: 0s - loss: 5.6966 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.0259s). Check your callbacks.\n",
      "1563/1562 [==============================] - 71s 46ms/step - loss: 4.2680 - accuracy: 0.0586 - val_loss: 3.9417 - val_accuracy: 0.1084\n",
      "Epoch 2/50\n",
      "1563/1562 [==============================] - 69s 44ms/step - loss: 3.6655 - accuracy: 0.1268 - val_loss: 3.5599 - val_accuracy: 0.1537\n",
      "Epoch 3/50\n",
      "1563/1562 [==============================] - 69s 44ms/step - loss: 3.2354 - accuracy: 0.1948 - val_loss: 3.0723 - val_accuracy: 0.2309\n",
      "Epoch 4/50\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 2.9001 - accuracy: 0.2546 - val_loss: 2.6350 - val_accuracy: 0.3169\n",
      "Epoch 5/50\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 2.6378 - accuracy: 0.3091 - val_loss: 2.6382 - val_accuracy: 0.3185\n",
      "Epoch 6/50\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 2.4190 - accuracy: 0.3593 - val_loss: 2.2525 - val_accuracy: 0.4051\n",
      "Epoch 7/50\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 2.2419 - accuracy: 0.3997 - val_loss: 2.0373 - val_accuracy: 0.4460\n",
      "Epoch 8/50\n",
      "1563/1562 [==============================] - 71s 46ms/step - loss: 2.0959 - accuracy: 0.4346 - val_loss: 2.1181 - val_accuracy: 0.4476\n",
      "Epoch 9/50\n",
      "1563/1562 [==============================] - 72s 46ms/step - loss: 1.9690 - accuracy: 0.4619 - val_loss: 1.8920 - val_accuracy: 0.4939\n",
      "Epoch 10/50\n",
      "1563/1562 [==============================] - 73s 47ms/step - loss: 1.8613 - accuracy: 0.4927 - val_loss: 1.7043 - val_accuracy: 0.5310\n",
      "Epoch 11/50\n",
      "1563/1562 [==============================] - 73s 47ms/step - loss: 1.7616 - accuracy: 0.5146 - val_loss: 1.7928 - val_accuracy: 0.5230\n",
      "Epoch 12/50\n",
      "1563/1562 [==============================] - 73s 47ms/step - loss: 1.6683 - accuracy: 0.5397 - val_loss: 1.6860 - val_accuracy: 0.5442\n",
      "Epoch 13/50\n",
      "1563/1562 [==============================] - 74s 47ms/step - loss: 1.5976 - accuracy: 0.5571 - val_loss: 1.7410 - val_accuracy: 0.5479\n",
      "Epoch 14/50\n",
      "1563/1562 [==============================] - 74s 47ms/step - loss: 1.5246 - accuracy: 0.5742 - val_loss: 1.6247 - val_accuracy: 0.5628\n",
      "Epoch 15/50\n",
      "1563/1562 [==============================] - 73s 47ms/step - loss: 1.4552 - accuracy: 0.5916 - val_loss: 1.7834 - val_accuracy: 0.5514\n",
      "Epoch 16/50\n",
      "1563/1562 [==============================] - ETA: 0s - loss: 1.3948 - accuracy: 0.6061\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1563/1562 [==============================] - 74s 48ms/step - loss: 1.3948 - accuracy: 0.6061 - val_loss: 1.6652 - val_accuracy: 0.5686\n",
      "Epoch 17/50\n",
      "1563/1562 [==============================] - 74s 47ms/step - loss: 1.2058 - accuracy: 0.6555 - val_loss: 1.4762 - val_accuracy: 0.6088\n",
      "Epoch 18/50\n",
      "1563/1562 [==============================] - 72s 46ms/step - loss: 1.1317 - accuracy: 0.6752 - val_loss: 1.4922 - val_accuracy: 0.6123\n",
      "Epoch 19/50\n",
      "1562/1562 [============================>.] - ETA: 0s - loss: 1.0860 - accuracy: 0.6867\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 1.0859 - accuracy: 0.6868 - val_loss: 1.6209 - val_accuracy: 0.5982\n",
      "Epoch 20/50\n",
      "1563/1562 [==============================] - 72s 46ms/step - loss: 0.9778 - accuracy: 0.7136 - val_loss: 1.3968 - val_accuracy: 0.6379\n",
      "Epoch 21/50\n",
      "1563/1562 [==============================] - 74s 47ms/step - loss: 0.9327 - accuracy: 0.7250 - val_loss: 1.3462 - val_accuracy: 0.6475\n",
      "Epoch 22/50\n",
      "1563/1562 [==============================] - 74s 47ms/step - loss: 0.9056 - accuracy: 0.7325 - val_loss: 1.3540 - val_accuracy: 0.6437\n",
      "Epoch 23/50\n",
      "1562/1562 [============================>.] - ETA: 0s - loss: 0.8785 - accuracy: 0.7394\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "1563/1562 [==============================] - 74s 47ms/step - loss: 0.8784 - accuracy: 0.7395 - val_loss: 1.3661 - val_accuracy: 0.6482\n",
      "Epoch 24/50\n",
      "1563/1562 [==============================] - 74s 47ms/step - loss: 0.8180 - accuracy: 0.7545 - val_loss: 1.3683 - val_accuracy: 0.6495\n",
      "Epoch 25/50\n",
      "1562/1562 [============================>.] - ETA: 0s - loss: 0.8052 - accuracy: 0.7601\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1563/1562 [==============================] - 74s 47ms/step - loss: 0.8050 - accuracy: 0.7602 - val_loss: 1.3669 - val_accuracy: 0.6513\n",
      "Epoch 26/50\n",
      "1563/1562 [==============================] - 71s 45ms/step - loss: 0.7695 - accuracy: 0.7676 - val_loss: 1.3511 - val_accuracy: 0.6556\n",
      "Epoch 27/50\n",
      "1563/1562 [==============================] - ETA: 0s - loss: 0.7632 - accuracy: 0.7703\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "1563/1562 [==============================] - 70s 45ms/step - loss: 0.7632 - accuracy: 0.7703 - val_loss: 1.3598 - val_accuracy: 0.6562\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "epoch = 50\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\", \n",
    "    optimizer = \"Adam\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(train_datagen.flow(train_data,train_label, batch_size = batch_size), \n",
    "                              steps_per_epoch = train_data.shape[0] / batch_size , \n",
    "                              validation_data = test_datagen.flow(test_data, test_label, batch_size = 32),\n",
    "                              validation_steps = test_data.shape[0] / batch_size,\n",
    "                              epochs = epoch,\n",
    "                              callbacks = [LR_function, EarlyStop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948ddfd3",
   "metadata": {},
   "source": [
    "# Evaluation_For_Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4023ae88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/421 [..............................] - ETA: 0s - loss: 4.4535 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.0269s). Check your callbacks.\n",
      "422/421 [==============================] - 19s 46ms/step - loss: 3.2335 - accuracy: 0.1404 - val_loss: 2.7147 - val_accuracy: 0.2493\n",
      "Epoch 2/50\n",
      "422/421 [==============================] - 18s 44ms/step - loss: 2.6997 - accuracy: 0.2293 - val_loss: 2.3961 - val_accuracy: 0.3107\n",
      "Epoch 3/50\n",
      "422/421 [==============================] - 18s 44ms/step - loss: 2.4437 - accuracy: 0.2850 - val_loss: 2.2287 - val_accuracy: 0.3187\n",
      "Epoch 4/50\n",
      "422/421 [==============================] - 18s 44ms/step - loss: 2.2434 - accuracy: 0.3319 - val_loss: 2.1503 - val_accuracy: 0.3740\n",
      "Epoch 5/50\n",
      "422/421 [==============================] - 18s 44ms/step - loss: 2.0657 - accuracy: 0.3788 - val_loss: 2.2833 - val_accuracy: 0.3720\n",
      "Epoch 6/50\n",
      "421/421 [============================>.] - ETA: 0s - loss: 1.8960 - accuracy: 0.4253\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 1.8964 - accuracy: 0.4252 - val_loss: 2.5192 - val_accuracy: 0.3500\n",
      "Epoch 7/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 1.6121 - accuracy: 0.5002 - val_loss: 1.4153 - val_accuracy: 0.5713\n",
      "Epoch 8/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 1.4904 - accuracy: 0.5341 - val_loss: 1.3809 - val_accuracy: 0.5780\n",
      "Epoch 9/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 1.4234 - accuracy: 0.5618 - val_loss: 1.5090 - val_accuracy: 0.5600\n",
      "Epoch 10/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 1.3300 - accuracy: 0.5864 - val_loss: 1.3134 - val_accuracy: 0.6193\n",
      "Epoch 11/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 1.2561 - accuracy: 0.6104 - val_loss: 1.2675 - val_accuracy: 0.6313\n",
      "Epoch 12/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 1.1823 - accuracy: 0.6339 - val_loss: 1.3758 - val_accuracy: 0.6040\n",
      "Epoch 13/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 1.1232 - accuracy: 0.6519 - val_loss: 1.2050 - val_accuracy: 0.6600\n",
      "Epoch 14/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 1.0614 - accuracy: 0.6658 - val_loss: 1.1793 - val_accuracy: 0.6527\n",
      "Epoch 15/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.9873 - accuracy: 0.6900 - val_loss: 1.0962 - val_accuracy: 0.6580\n",
      "Epoch 16/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.9276 - accuracy: 0.7141 - val_loss: 1.1043 - val_accuracy: 0.6740\n",
      "Epoch 17/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.8751 - accuracy: 0.7276 - val_loss: 0.9781 - val_accuracy: 0.7133\n",
      "Epoch 18/50\n",
      "422/421 [==============================] - 19s 45ms/step - loss: 0.8257 - accuracy: 0.7424 - val_loss: 1.1536 - val_accuracy: 0.6873\n",
      "Epoch 19/50\n",
      "421/421 [============================>.] - ETA: 0s - loss: 0.7876 - accuracy: 0.7519\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.7874 - accuracy: 0.7520 - val_loss: 0.9872 - val_accuracy: 0.7140\n",
      "Epoch 20/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.6143 - accuracy: 0.8059 - val_loss: 0.9158 - val_accuracy: 0.7380\n",
      "Epoch 21/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.5293 - accuracy: 0.8333 - val_loss: 0.8282 - val_accuracy: 0.7740\n",
      "Epoch 22/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.5071 - accuracy: 0.8339 - val_loss: 0.8839 - val_accuracy: 0.7520\n",
      "Epoch 23/50\n",
      "421/421 [============================>.] - ETA: 0s - loss: 0.4861 - accuracy: 0.8418\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.4866 - accuracy: 0.8416 - val_loss: 0.8877 - val_accuracy: 0.7540\n",
      "Epoch 24/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.3945 - accuracy: 0.8717 - val_loss: 0.7791 - val_accuracy: 0.7807\n",
      "Epoch 25/50\n",
      "422/421 [==============================] - 18s 44ms/step - loss: 0.3600 - accuracy: 0.8857 - val_loss: 0.8528 - val_accuracy: 0.7667\n",
      "Epoch 26/50\n",
      "422/421 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.8930\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.3296 - accuracy: 0.8930 - val_loss: 0.8596 - val_accuracy: 0.7720\n",
      "Epoch 27/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.2940 - accuracy: 0.9075 - val_loss: 0.7735 - val_accuracy: 0.7827\n",
      "Epoch 28/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.2792 - accuracy: 0.9116 - val_loss: 0.7997 - val_accuracy: 0.7847\n",
      "Epoch 29/50\n",
      "421/421 [============================>.] - ETA: 0s - loss: 0.2552 - accuracy: 0.9191\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.2550 - accuracy: 0.9192 - val_loss: 0.7838 - val_accuracy: 0.7860\n",
      "Epoch 30/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.2433 - accuracy: 0.9201 - val_loss: 0.7929 - val_accuracy: 0.7873\n",
      "Epoch 31/50\n",
      "421/421 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.9243\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.2380 - accuracy: 0.9244 - val_loss: 0.7995 - val_accuracy: 0.7873\n",
      "Epoch 32/50\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.2156 - accuracy: 0.9330 - val_loss: 0.7969 - val_accuracy: 0.7893\n",
      "Epoch 33/50\n",
      "421/421 [============================>.] - ETA: 0s - loss: 0.2259 - accuracy: 0.9266\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "422/421 [==============================] - 19s 44ms/step - loss: 0.2261 - accuracy: 0.9266 - val_loss: 0.7931 - val_accuracy: 0.7860\n",
      "Epoch 00033: early stopping\n"
     ]
    }
   ],
   "source": [
    "epoch = 50\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\", \n",
    "    optimizer = \"Adam\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(train_datagen.flow(train_data,train_label, batch_size = batch_size), \n",
    "                    steps_per_epoch = train_data.shape[0] / batch_size , \n",
    "                    validation_data = val_datagen.flow(val_data, val_label),\n",
    "                    epochs = epoch,\n",
    "                    callbacks = [LR_function, EarlyStop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8aa70",
   "metadata": {},
   "source": [
    "# Evaluation_For_Read - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c77d2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-d31d6631806c>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "  1/375 [..............................] - ETA: 0s - loss: 4.5477 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0170s vs `on_train_batch_end` time: 0.0269s). Check your callbacks.\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 3.5882 - accuracy: 0.1125 - val_loss: 3.1865 - val_accuracy: 0.1436\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 2.9535 - accuracy: 0.1813 - val_loss: 2.4760 - val_accuracy: 0.2580\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 17s 44ms/step - loss: 2.6821 - accuracy: 0.2327 - val_loss: 2.4397 - val_accuracy: 0.3112\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 2.4547 - accuracy: 0.2812 - val_loss: 2.4706 - val_accuracy: 0.2806\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 2.2795 - accuracy: 0.3190\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 2.2795 - accuracy: 0.3190 - val_loss: 2.8142 - val_accuracy: 0.3125\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 2.0259 - accuracy: 0.3854 - val_loss: 1.8519 - val_accuracy: 0.4455\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 1.9200 - accuracy: 0.4169 - val_loss: 1.9948 - val_accuracy: 0.4069\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 1.8623 - accuracy: 0.4349 - val_loss: 1.7700 - val_accuracy: 0.4694\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 1.7682 - accuracy: 0.4622 - val_loss: 1.8971 - val_accuracy: 0.4588\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 1.6872 - accuracy: 0.4885 - val_loss: 1.6620 - val_accuracy: 0.5226\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 1.5952 - accuracy: 0.5113 - val_loss: 1.8939 - val_accuracy: 0.4880\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 1.5193 - accuracy: 0.5390 - val_loss: 1.6413 - val_accuracy: 0.5120\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 1.4384 - accuracy: 0.5641 - val_loss: 1.4971 - val_accuracy: 0.5559\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 1.3840 - accuracy: 0.5822 - val_loss: 1.3779 - val_accuracy: 0.5691\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 1.2911 - accuracy: 0.6055 - val_loss: 1.3945 - val_accuracy: 0.6077\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 1.2329 - accuracy: 0.6212\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 1.2329 - accuracy: 0.6212 - val_loss: 1.5084 - val_accuracy: 0.5372\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 1.0463 - accuracy: 0.6777 - val_loss: 1.1235 - val_accuracy: 0.6463\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.9657 - accuracy: 0.7038 - val_loss: 1.0811 - val_accuracy: 0.6543\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.9187 - accuracy: 0.7211 - val_loss: 1.1267 - val_accuracy: 0.6676\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.8735 - accuracy: 0.7342 - val_loss: 0.9821 - val_accuracy: 0.6862\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.8403 - accuracy: 0.7377 - val_loss: 1.1538 - val_accuracy: 0.6769\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.7857 - accuracy: 0.7548\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.7857 - accuracy: 0.7548 - val_loss: 1.1082 - val_accuracy: 0.6742\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.6777 - accuracy: 0.7896 - val_loss: 0.9576 - val_accuracy: 0.7234\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.6192 - accuracy: 0.8083 - val_loss: 0.8662 - val_accuracy: 0.7380\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.5950 - accuracy: 0.8152 - val_loss: 0.9094 - val_accuracy: 0.7114\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.8167\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.5747 - accuracy: 0.8167 - val_loss: 0.8675 - val_accuracy: 0.7434\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.5159 - accuracy: 0.8421 - val_loss: 0.9212 - val_accuracy: 0.7221\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.8499\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.4813 - accuracy: 0.8499 - val_loss: 0.9658 - val_accuracy: 0.7340\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.4652 - accuracy: 0.8571 - val_loss: 0.9364 - val_accuracy: 0.7434\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4478 - accuracy: 0.8615\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.4478 - accuracy: 0.8615 - val_loss: 0.9618 - val_accuracy: 0.7301\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.4137 - accuracy: 0.8741 - val_loss: 0.9374 - val_accuracy: 0.7354\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.8709\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.4216 - accuracy: 0.8709 - val_loss: 0.8795 - val_accuracy: 0.7447\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.4146 - accuracy: 0.8731 - val_loss: 0.8055 - val_accuracy: 0.7620\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.4129 - accuracy: 0.8742 - val_loss: 0.8725 - val_accuracy: 0.7513\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.3999 - accuracy: 0.8764 - val_loss: 0.9174 - val_accuracy: 0.7301\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.3975 - accuracy: 0.8764 - val_loss: 0.9375 - val_accuracy: 0.7566\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.3802 - accuracy: 0.8794 - val_loss: 0.8508 - val_accuracy: 0.7620\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.3944 - accuracy: 0.8769 - val_loss: 0.8294 - val_accuracy: 0.7779\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.3951 - accuracy: 0.8774 - val_loss: 0.9031 - val_accuracy: 0.7553\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.3889 - accuracy: 0.8804 - val_loss: 0.9613 - val_accuracy: 0.7527\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.4005 - accuracy: 0.8728 - val_loss: 1.0239 - val_accuracy: 0.7247\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.3846 - accuracy: 0.8802 - val_loss: 0.8519 - val_accuracy: 0.7660\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.3801 - accuracy: 0.8817 - val_loss: 0.8178 - val_accuracy: 0.7553\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.3811 - accuracy: 0.8806 - val_loss: 0.9922 - val_accuracy: 0.7194\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.3748 - accuracy: 0.8851 - val_loss: 0.8581 - val_accuracy: 0.7553\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.3828 - accuracy: 0.8813 - val_loss: 0.9639 - val_accuracy: 0.7394\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.3598 - accuracy: 0.8883 - val_loss: 0.8444 - val_accuracy: 0.7566\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.3589 - accuracy: 0.8873 - val_loss: 0.8925 - val_accuracy: 0.7580\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.3642 - accuracy: 0.8898 - val_loss: 0.8058 - val_accuracy: 0.7699\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 17s 45ms/step - loss: 0.3655 - accuracy: 0.8867 - val_loss: 0.8456 - val_accuracy: 0.7540\n"
     ]
    }
   ],
   "source": [
    "epoch = 50\n",
    "batch_size = 256\n",
    "\n",
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\", \n",
    "    optimizer = \"Adam\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit_generator(train_datagen.flow(train_data,train_label, batch_size = batch_size), \n",
    "                              steps_per_epoch = train_data.shape[0] / batch_size , \n",
    "                              validation_data = val_datagen.flow(val_data, val_label),\n",
    "                              epochs = epoch,\n",
    "                              callbacks = [LR_function, EarlyStop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a65e14d",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b4c22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "testdata_path = r\"C:\\Users\\foo\\Desktop\\CNN\\Testing_data-2\"\n",
    "test_data = []\n",
    "\n",
    "for dirs, subdirs, files in os.walk(testdata_path):\n",
    "    numbers_of_testdata += len(files)\n",
    "\n",
    "testfileName = [file for file in listdir(testdata_path) if isfile(join(testdata_path, file))]\n",
    "\n",
    "for num, fname in enumerate(testfileName):\n",
    "    path = testdata_path + r\"\\\\\" + fname\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)        \n",
    "    test_data.append(img)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "print(test_data.shape)\n",
    "\n",
    "########################################################################################\n",
    "test_data = test_data.astype('float32')\n",
    "test_data /= 255\n",
    "########################################################################################\n",
    "prediction = model.predict(test_data)\n",
    "filecounter = 0\n",
    "with open(\"410785018.txt\", 'w') as f:\n",
    "    for predict in prediction:\n",
    "        path = testdata_path + r'\\\\' + testfileName[filecounter]\n",
    "        txt_name = os.path.splitext(testfileName[filecounter].split('.')[0])[0]\n",
    "        f.write(txt_name + \" \" + (np.argmax(predict)).astype(str) + \"\\n\")\n",
    "        filecounter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aca456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
